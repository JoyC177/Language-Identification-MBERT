{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47d4d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a39d8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_pre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7a25991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Nd', 'Cc', 'No', 'Nl', 'Co', 'Cn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8600e81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Lu       Ll      Zs      Po     Pd     Ps     Pe       Lo  \\\n",
      "Language                                                                  \n",
      "ace       13.472  223.534  43.992   7.480  0.784  0.434  0.432    0.530   \n",
      "afr       13.716  331.412  69.256   9.190  1.276  0.636  0.636    0.068   \n",
      "als       21.422  265.276  56.234   8.472  0.900  0.796  0.710    0.096   \n",
      "amh        0.676    4.290  56.952   8.312  0.534  0.944  0.934  217.340   \n",
      "ang       10.642  207.452  41.732   6.336  0.348  0.542  0.532    0.190   \n",
      "...          ...      ...     ...     ...    ...    ...    ...      ...   \n",
      "yid        0.678    4.182  59.784   8.054  0.506  0.490  0.490  277.694   \n",
      "yor       13.836  242.096  62.848   7.888  1.432  1.120  1.122    0.514   \n",
      "zea       10.920  227.444  50.208  11.152  0.850  0.382  0.380    0.146   \n",
      "zh-yue     3.958   35.150   7.086  14.244  0.376  2.500  2.498  136.054   \n",
      "zho        5.762   12.770   2.656  17.778  0.372  2.296  2.300  194.570   \n",
      "\n",
      "             Mc     Mn     Pi     Pf     Cf     Sm     Lm     So     Sc  \\\n",
      "Language                                                                  \n",
      "ace       0.010  0.028  0.008  0.064  0.032  0.004  0.002  0.022  0.000   \n",
      "afr       0.000  0.000  0.074  0.454  0.010  0.020  0.004  0.006  0.036   \n",
      "als       0.004  0.020  0.202  0.174  0.004  0.018  0.050  0.012  0.002   \n",
      "amh       0.006  0.340  0.538  0.564  0.000  0.034  0.006  0.078  0.004   \n",
      "ang       0.034  0.048  0.008  0.006  0.002  0.006  0.004  0.004  0.016   \n",
      "...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "yid       0.006  2.932  0.006  0.006  0.092  0.010  0.004  0.020  0.004   \n",
      "yor       0.038  4.464  0.072  0.096  0.030  0.008  0.152  0.002  0.012   \n",
      "zea       0.002  0.010  0.090  0.410  0.004  0.004  0.000  0.002  0.002   \n",
      "zh-yue    0.018  0.022  0.032  0.038  0.016  0.050  0.078  0.034  0.008   \n",
      "zho       0.000  0.010  0.622  0.648  0.006  0.054  0.004  0.016  0.006   \n",
      "\n",
      "             Sk     Pc  \n",
      "Language                \n",
      "ace       0.000  0.000  \n",
      "afr       0.000  0.000  \n",
      "als       0.002  0.000  \n",
      "amh       0.000  0.002  \n",
      "ang       0.000  0.000  \n",
      "...         ...    ...  \n",
      "yid       0.000  0.010  \n",
      "yor       0.016  0.000  \n",
      "zea       0.014  0.000  \n",
      "zh-yue    0.002  0.000  \n",
      "zho       0.000  0.000  \n",
      "\n",
      "[234 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "df3 = df.groupby([\"Language\"]).mean()\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2fdf7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234, 19)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "X = df3.to_numpy()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47ed8b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234, 10)\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold(0.5)\n",
    "new_x = selector.fit_transform(X)\n",
    "print(new_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc11face",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd894413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         est\n",
      "1         swe\n",
      "2         mai\n",
      "3         oci\n",
      "4         tha\n",
      "         ... \n",
      "117495    bos\n",
      "117496    lim\n",
      "117497    lzh\n",
      "117498    dan\n",
      "117499    isl\n",
      "Name: Language, Length: 117500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df4 = df['Language']\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7f07870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Lang_ace  Lang_afr  Lang_als  Lang_amh  Lang_ang  Lang_ara  Lang_arg  \\\n",
      "0              0         0         0         0         0         0         0   \n",
      "1              0         0         0         0         0         0         0   \n",
      "2              0         0         0         0         0         0         0   \n",
      "3              0         0         0         0         0         0         0   \n",
      "4              0         0         0         0         0         0         0   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "117495         0         0         0         0         0         0         0   \n",
      "117496         0         0         0         0         0         0         0   \n",
      "117497         0         0         0         0         0         0         0   \n",
      "117498         0         0         0         0         0         0         0   \n",
      "117499         0         0         0         0         0         0         0   \n",
      "\n",
      "        Lang_arz  Lang_asm  Lang_ast  ...  Lang_wln  Lang_wol  Lang_wuu  \\\n",
      "0              0         0         0  ...         0         0         0   \n",
      "1              0         0         0  ...         0         0         0   \n",
      "2              0         0         0  ...         0         0         0   \n",
      "3              0         0         0  ...         0         0         0   \n",
      "4              0         0         0  ...         0         0         0   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "117495         0         0         0  ...         0         0         0   \n",
      "117496         0         0         0  ...         0         0         0   \n",
      "117497         0         0         0  ...         0         0         0   \n",
      "117498         0         0         0  ...         0         0         0   \n",
      "117499         0         0         0  ...         0         0         0   \n",
      "\n",
      "        Lang_xho  Lang_xmf  Lang_yid  Lang_yor  Lang_zea  Lang_zh-yue  \\\n",
      "0              0         0         0         0         0            0   \n",
      "1              0         0         0         0         0            0   \n",
      "2              0         0         0         0         0            0   \n",
      "3              0         0         0         0         0            0   \n",
      "4              0         0         0         0         0            0   \n",
      "...          ...       ...       ...       ...       ...          ...   \n",
      "117495         0         0         0         0         0            0   \n",
      "117496         0         0         0         0         0            0   \n",
      "117497         0         0         0         0         0            0   \n",
      "117498         0         0         0         0         0            0   \n",
      "117499         0         0         0         0         0            0   \n",
      "\n",
      "        Lang_zho  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "...          ...  \n",
      "117495         0  \n",
      "117496         0  \n",
      "117497         0  \n",
      "117498         0  \n",
      "117499         0  \n",
      "\n",
      "[117500 rows x 234 columns]\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.get_dummies(df['Language'], prefix='Lang')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d43841ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Lu   Ll   Zs  Po  Pd  Ps  Pe   Lo  Mc  Mn  Pi  Pf  Cf  Sm  Lm  So  Sc  \\\n",
      "0        9  283   45   6   2   0   0    0   0   0   0   0   0   0   0   0   0   \n",
      "1       17  120   31  11   3   3   3    0   0   0   0   0   0   0   0   0   0   \n",
      "2        0    0   63   8   0   0   0  237  61  67   0   0   0   0   0   0   0   \n",
      "3       42  750  159  37   1  16  15    0   0   0   2   4   0   0   0   0   0   \n",
      "4        3   15   13   1   0   1   1  179   0  41   0   0   0   0   0   0   0   \n",
      "...     ..  ...  ...  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
      "117495  26  792  187  27   0   3   3    0   0   0   0   0   0   0   0   0   0   \n",
      "117496  14  200   45   9   1   0   0    0   0   0   0   0   0   0   0   0   0   \n",
      "117497   0    0    0  34   0   1   1  195   0   0   0   0   0   0   0   0   0   \n",
      "117498  19  495  106  16   0   0   0    0   0   0   0   0   0   0   0   0   0   \n",
      "117499   6  238   46   4   0   0   0    0   0   0   0   0   0   0   0   0   0   \n",
      "\n",
      "        Sk  Pc  \n",
      "0        0   0  \n",
      "1        0   0  \n",
      "2        0   0  \n",
      "3        0   0  \n",
      "4        0   0  \n",
      "...     ..  ..  \n",
      "117495   0   0  \n",
      "117496   0   0  \n",
      "117497   0   0  \n",
      "117498   0   0  \n",
      "117499   0   0  \n",
      "\n",
      "[117500 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "x = df.drop('Language', axis=1).drop('index', axis=1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e35d96e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Lu        Ll        Zs        Po        Pd        Ps        Pe  \\\n",
      "0       0.026087  0.820290  0.130435  0.017391  0.005797  0.000000  0.000000   \n",
      "1       0.090426  0.638298  0.164894  0.058511  0.015957  0.015957  0.015957   \n",
      "2       0.000000  0.000000  0.144495  0.018349  0.000000  0.000000  0.000000   \n",
      "3       0.040936  0.730994  0.154971  0.036062  0.000975  0.015595  0.014620   \n",
      "4       0.011811  0.059055  0.051181  0.003937  0.000000  0.003937  0.003937   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "117495  0.025048  0.763006  0.180154  0.026012  0.000000  0.002890  0.002890   \n",
      "117496  0.052045  0.743494  0.167286  0.033457  0.003717  0.000000  0.000000   \n",
      "117497  0.000000  0.000000  0.000000  0.147186  0.000000  0.004329  0.004329   \n",
      "117498  0.029874  0.778302  0.166667  0.025157  0.000000  0.000000  0.000000   \n",
      "117499  0.020408  0.809524  0.156463  0.013605  0.000000  0.000000  0.000000   \n",
      "\n",
      "              Lo        Mc        Mn        Pi        Pf   Cf   Sm   Lm   So  \\\n",
      "0       0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
      "1       0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
      "2       0.543578  0.139908  0.153670  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
      "3       0.000000  0.000000  0.000000  0.001949  0.003899  0.0  0.0  0.0  0.0   \n",
      "4       0.704724  0.000000  0.161417  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
      "...          ...       ...       ...       ...       ...  ...  ...  ...  ...   \n",
      "117495  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
      "117496  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
      "117497  0.844156  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
      "117498  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
      "117499  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
      "\n",
      "         Sc   Sk   Pc  \n",
      "0       0.0  0.0  0.0  \n",
      "1       0.0  0.0  0.0  \n",
      "2       0.0  0.0  0.0  \n",
      "3       0.0  0.0  0.0  \n",
      "4       0.0  0.0  0.0  \n",
      "...     ...  ...  ...  \n",
      "117495  0.0  0.0  0.0  \n",
      "117496  0.0  0.0  0.0  \n",
      "117497  0.0  0.0  0.0  \n",
      "117498  0.0  0.0  0.0  \n",
      "117499  0.0  0.0  0.0  \n",
      "\n",
      "[117500 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "h = x.div(x.sum(axis=1), axis=0)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9313067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lu    0.034519\n",
      "Ll    0.763574\n",
      "Zs    0.165773\n",
      "Po    0.028267\n",
      "Pd    0.002672\n",
      "Ps    0.002062\n",
      "Pe    0.002050\n",
      "Lo    0.000000\n",
      "Mc    0.000000\n",
      "Mn    0.000010\n",
      "Pi    0.000156\n",
      "Pf    0.000790\n",
      "Cf    0.000000\n",
      "Sm    0.000068\n",
      "Lm    0.000000\n",
      "So    0.000060\n",
      "Sc    0.000000\n",
      "Sk    0.000000\n",
      "Pc    0.000000\n",
      "Name: vls, dtype: float64\n",
      "Lu    0.029633\n",
      "Ll    0.770011\n",
      "Zs    0.163683\n",
      "Po    0.031010\n",
      "Pd    0.002109\n",
      "Ps    0.001651\n",
      "Pe    0.001655\n",
      "Lo    0.000022\n",
      "Mc    0.000000\n",
      "Mn    0.000000\n",
      "Pi    0.000038\n",
      "Pf    0.000151\n",
      "Cf    0.000000\n",
      "Sm    0.000008\n",
      "Lm    0.000000\n",
      "So    0.000000\n",
      "Sc    0.000004\n",
      "Sk    0.000025\n",
      "Pc    0.000000\n",
      "Name: lim, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "h2 = h.join(df[\"Language\"]).groupby([\"Language\"]).mean()\n",
    "# print(h2.loc[h2[\"Language\"].isin(['wuu', 'zho', 'nan', 'lzh'])])\n",
    "# print(h2.loc['zho'])\n",
    "# print(h2.loc['nan'])\n",
    "print(h2.loc['vls'])\n",
    "print(h2.loc['lim'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0afff547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Spliiting data into test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, df2, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model\n",
    "model = RandomForestClassifier(n_estimators=50, n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b067da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting feature importances\n",
    "features = df.drop('Language', axis=1).columns\n",
    "features = features.drop('index')\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22c22b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Spliiting data into test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(h, df4, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a616c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model\n",
    "model1 = RandomForestClassifier(n_estimators=50, n_jobs=-1, random_state=42)\n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c87af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting feature importances\n",
    "features = df.drop('Language', axis=1).columns\n",
    "features = features.drop('index')\n",
    "importances = model1.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "064d4fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:20:26] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:576: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nils/miniconda3/envs/std/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/nils/miniconda3/envs/std/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[17:20:26] /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/data/data.cc:592: Check failed: labels_.Size() == num_row_ (117500 vs. 94000) : Size of labels must equal to number of rows.\nStack trace:\n  [bt] (0) /home/nils/miniconda3/envs/std/lib/libxgboost.so(+0x98154) [0x7f5a283a3154]\n  [bt] (1) /home/nils/miniconda3/envs/std/lib/libxgboost.so(xgboost::MetaInfo::Validate(int) const+0x319) [0x7f5a28437ec9]\n  [bt] (2) /home/nils/miniconda3/envs/std/lib/libxgboost.so(+0x1ae06b) [0x7f5a284b906b]\n  [bt] (3) /home/nils/miniconda3/envs/std/lib/libxgboost.so(+0x1b6ee3) [0x7f5a284c1ee3]\n  [bt] (4) /home/nils/miniconda3/envs/std/lib/libxgboost.so(XGBoosterUpdateOneIter+0x61) [0x7f5a283a8681]\n  [bt] (5) /home/nils/miniconda3/envs/std/lib/python3.9/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5a681689dd]\n  [bt] (6) /home/nils/miniconda3/envs/std/lib/python3.9/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5a68168067]\n  [bt] (7) /home/nils/miniconda3/envs/std/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x91e0) [0x7f5a681771e0]\n  [bt] (8) /home/nils/miniconda3/envs/std/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x8568) [0x7f5a68176568]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(h, df4, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.20\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_encoded_y\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/std/lib/python3.9/site-packages/xgboost/core.py:506\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    505\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/std/lib/python3.9/site-packages/xgboost/sklearn.py:1250\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1230\u001b[0m model, feval, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, eval_metric, params)\n\u001b[1;32m   1231\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1232\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1233\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     label_transform\u001b[38;5;241m=\u001b[39mlabel_transform,\n\u001b[1;32m   1248\u001b[0m )\n\u001b[0;32m-> 1250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/std/lib/python3.9/site-packages/xgboost/training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, evals\u001b[38;5;241m=\u001b[39m(), obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    116\u001b[0m           maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, evals_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    117\u001b[0m           verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xgb_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;124;03m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    Booster : a trained booster model\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     bst \u001b[38;5;241m=\u001b[39m \u001b[43m_train_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bst\n",
      "File \u001b[0;32m~/miniconda3/envs/std/lib/python3.9/site-packages/xgboost/training.py:81\u001b[0m, in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/std/lib/python3.9/site-packages/xgboost/core.py:1680\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1680\u001b[0m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1684\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/std/lib/python3.9/site-packages/xgboost/core.py:218\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [17:20:26] /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/data/data.cc:592: Check failed: labels_.Size() == num_row_ (117500 vs. 94000) : Size of labels must equal to number of rows.\nStack trace:\n  [bt] (0) /home/nils/miniconda3/envs/std/lib/libxgboost.so(+0x98154) [0x7f5a283a3154]\n  [bt] (1) /home/nils/miniconda3/envs/std/lib/libxgboost.so(xgboost::MetaInfo::Validate(int) const+0x319) [0x7f5a28437ec9]\n  [bt] (2) /home/nils/miniconda3/envs/std/lib/libxgboost.so(+0x1ae06b) [0x7f5a284b906b]\n  [bt] (3) /home/nils/miniconda3/envs/std/lib/libxgboost.so(+0x1b6ee3) [0x7f5a284c1ee3]\n  [bt] (4) /home/nils/miniconda3/envs/std/lib/libxgboost.so(XGBoosterUpdateOneIter+0x61) [0x7f5a283a8681]\n  [bt] (5) /home/nils/miniconda3/envs/std/lib/python3.9/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5a681689dd]\n  [bt] (6) /home/nils/miniconda3/envs/std/lib/python3.9/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5a68168067]\n  [bt] (7) /home/nils/miniconda3/envs/std/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x91e0) [0x7f5a681771e0]\n  [bt] (8) /home/nils/miniconda3/envs/std/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x8568) [0x7f5a68176568]\n\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(df4)\n",
    "label_encoded_y = label_encoder.transform(df4)\n",
    "\n",
    "# Spliiting data into test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(h, df4, test_size=0.20, random_state=42)\n",
    "\n",
    "model = XGBClassifier(n_estimators=100, eval_metric='mlogloss', verbose=1, n_jobs=-1)\n",
    "model.fit(X_train, label_encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2296d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2945531914893617\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(label_encoded_y1, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0377d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e8c4bf9a1a9f7e7cc011ed0f1048bb31683f8a7a3e3a00930cb02ac8df58bef2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
